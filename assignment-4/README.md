[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/OaLM6ffB)
[![Open in Visual Studio Code](https://classroom.github.com/assets/open-in-vscode-718a45dd9cf7e7f842a935f5ebbe5719a5e09af4491e668f4dbf3b35d5cca122.svg)](https://classroom.github.com/online_ide?assignment_repo_id=10852519&assignment_repo_type=AssignmentRepo)
# Assignment 4: Principal Component Analysis (PCA)

## Deadline: 25, Apr., 2023 23:59 (Tue)

In assignment 4, you will be required to finish a series of coding tasks about principal component analysis (PCA) and feature-based aggregation with PySpark. This assignement is time-consuming, so please **start early**.

## Assignment

This assignment, composed of 4 parts, is worth 8 points. You will find detailed information of each part and corresponding instructions in the `.ipynb` file. Each part is marked based on the difficulty.

We provide you a skeleton in this assignment. You should fill the spaces with your own code to make the Jupyter notebook run as required.

The assignment should be finished on [Databricks](https://community.cloud.databricks.com/). Please first go through the [Spark tutorial](https://canvas.ust.hk/courses/47941/discussion_topics/409967) if you are not yet familiar with Spark and Databricks.

You may find some APIs unfamiliar to you. Please follow our instructions in the notebook, which will lead you to get started better.

## Grading

We will run your code and test your results with a standard testing script. Each part will be graded individually, but there may be dependencies between each part, so please don't skip any of the parts.
